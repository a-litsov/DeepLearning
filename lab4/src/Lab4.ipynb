{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH = 128\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "train_data = datagen.flow_from_directory('/kaggle/input/intel-image-classification/seg_train/seg_train/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=14034,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "test_data = datagen.flow_from_directory('/kaggle/input/intel-image-classification/seg_test/seg_test/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=3000,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "\n",
    "#train_images, train_labels = train_data.next()\n",
    "#test_images, test_labels = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = train_data.next()\n",
    "test_images, test_labels = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14034, 150, 150, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = np.reshape( train_images,  (len(train_images),  150 ,  150 ,  3 ))   # adapt this if using `channels_first` image data format\n",
    "#test_images =  np.reshape( test_images,  (len(test_images),  150 ,  150 ,  3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сеть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простой автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "def create_dense_ae():\n",
    "    \n",
    "    encoding_dim = 1000\n",
    "\n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "    flat_img = Flatten()(input_img)\n",
    "\n",
    "    encoded = Dense(encoding_dim, activation='relu')(flat_img)\n",
    "    \n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    flat_decoded = Dense(150*150*3, activation='relu')(input_encoded)\n",
    "    decoded = Reshape((150, 150, 3))(flat_decoded)\n",
    "\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1000)              67501000  \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 150, 150, 3)       67567500  \n",
      "=================================================================\n",
      "Total params: 135,068,500\n",
      "Trainable params: 135,068,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 7.0550 - accuracy: 0.3519 - val_loss: 6.7996 - val_accuracy: 0.3858\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 5.3675 - accuracy: 0.3946 - val_loss: 4.3050 - val_accuracy: 0.4275\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 4.1253 - accuracy: 0.4532 - val_loss: 3.9799 - val_accuracy: 0.4609\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.6139 - accuracy: 0.5084 - val_loss: 3.4545 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.4061 - accuracy: 0.5510 - val_loss: 3.4108 - val_accuracy: 0.5237\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3848 - accuracy: 0.5634 - val_loss: 3.3874 - val_accuracy: 0.5082\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3668 - accuracy: 0.5771 - val_loss: 3.3774 - val_accuracy: 0.5966\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3496 - accuracy: 0.5867 - val_loss: 3.3537 - val_accuracy: 0.5617\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3322 - accuracy: 0.5933 - val_loss: 3.3408 - val_accuracy: 0.6021\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3214 - accuracy: 0.5979 - val_loss: 3.3315 - val_accuracy: 0.5564\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3145 - accuracy: 0.6052 - val_loss: 3.3235 - val_accuracy: 0.5218\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3066 - accuracy: 0.6069 - val_loss: 3.3169 - val_accuracy: 0.6319\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3023 - accuracy: 0.6117 - val_loss: 3.3123 - val_accuracy: 0.5925\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2967 - accuracy: 0.6150 - val_loss: 3.3085 - val_accuracy: 0.6360\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2919 - accuracy: 0.6162 - val_loss: 3.3028 - val_accuracy: 0.6121\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2753 - accuracy: 0.6208 - val_loss: 3.2842 - val_accuracy: 0.5977\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2661 - accuracy: 0.6229 - val_loss: 3.2794 - val_accuracy: 0.6321\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2622 - accuracy: 0.6276 - val_loss: 3.2753 - val_accuracy: 0.6187\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2596 - accuracy: 0.6274 - val_loss: 3.2715 - val_accuracy: 0.6567\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2566 - accuracy: 0.6275 - val_loss: 3.2692 - val_accuracy: 0.6206\n",
      "Time:  0:05:43.096131\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, autoencoder = create_dense_ae()\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "time_start = datetime.now()\n",
    "autoencoder.fit( train_images, train_images, epochs= 20, batch_size= 128, shuffle= True, \n",
    "                validation_data= (test_images,  test_images))\n",
    "print('Time: ', datetime.now() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              67501000  \n",
      "=================================================================\n",
      "Total params: 67,501,000\n",
      "Trainable params: 67,501,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1000)              67501000  \n",
      "_________________________________________________________________\n",
      "dens_ (Model)                (None, 6)                 687702    \n",
      "=================================================================\n",
      "Total params: 68,188,702\n",
      "Trainable params: 68,188,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 597us/step - loss: 9.9767 - accuracy: 0.2338 - val_loss: 3.5786 - val_accuracy: 0.2297\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.6494 - accuracy: 0.4027 - val_loss: 1.4695 - val_accuracy: 0.4330\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.3192 - accuracy: 0.4913 - val_loss: 1.3567 - val_accuracy: 0.4810\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.2333 - accuracy: 0.5324 - val_loss: 1.2093 - val_accuracy: 0.5297\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.1880 - accuracy: 0.5508 - val_loss: 1.2213 - val_accuracy: 0.5343\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 8s 575us/step - loss: 1.1378 - accuracy: 0.5671 - val_loss: 1.3195 - val_accuracy: 0.5203\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.1133 - accuracy: 0.5824 - val_loss: 1.1829 - val_accuracy: 0.5673\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.0893 - accuracy: 0.5973 - val_loss: 1.2165 - val_accuracy: 0.5410\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 8s 581us/step - loss: 1.0653 - accuracy: 0.6001 - val_loss: 1.1358 - val_accuracy: 0.5767\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 1.0430 - accuracy: 0.6081 - val_loss: 1.2547 - val_accuracy: 0.5533\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 8s 591us/step - loss: 1.0223 - accuracy: 0.6195 - val_loss: 1.0945 - val_accuracy: 0.5957\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 8s 586us/step - loss: 0.9920 - accuracy: 0.6264 - val_loss: 1.5100 - val_accuracy: 0.5533\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 8s 586us/step - loss: 0.9826 - accuracy: 0.6332 - val_loss: 1.1554 - val_accuracy: 0.5633\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 8s 585us/step - loss: 0.9601 - accuracy: 0.6355 - val_loss: 1.1780 - val_accuracy: 0.5643\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 0.9563 - accuracy: 0.6400 - val_loss: 1.1385 - val_accuracy: 0.5767\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 8s 584us/step - loss: 0.9332 - accuracy: 0.6506 - val_loss: 1.2617 - val_accuracy: 0.5653\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 8s 585us/step - loss: 0.9154 - accuracy: 0.6561 - val_loss: 1.1614 - val_accuracy: 0.5847\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 0.9011 - accuracy: 0.6625 - val_loss: 1.1076 - val_accuracy: 0.6107\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 8s 583us/step - loss: 0.8831 - accuracy: 0.6699 - val_loss: 1.4644 - val_accuracy: 0.5413\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 8s 586us/step - loss: 0.8731 - accuracy: 0.6727 - val_loss: 1.2962 - val_accuracy: 0.5033\n",
      "Time:  0:02:44.153719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fb9edd35278>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense_auto(autoencoder):\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    encoder_dim = Input(shape=(1000,))\n",
    "    \n",
    "    dens_1 = Dense(512, activation='relu')(encoder_dim)\n",
    "    dens_2 = Dense(256, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(128, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(64, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(32, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(16, activation='relu')(dens_5)\n",
    "    dens = Dense(6, activation='softmax')(dens_6)\n",
    "\n",
    "    \n",
    "    auto = Model(input_img, autoencoder.layers[1](input_img), name=\"encoder\")    \n",
    "    dens_ = Model(encoder_dim, dens, name=\"dens_\")\n",
    "    fc = Model(input_img, dens_(auto(input_img)), name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    time_start = datetime.now()\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    \n",
    "    return fc\n",
    "\n",
    "dense_auto(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              67501000  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 68,188,702\n",
      "Trainable params: 68,188,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 601us/step - loss: 7.1054 - accuracy: 0.1912 - val_loss: 1.8102 - val_accuracy: 0.2790\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 8s 581us/step - loss: 1.7100 - accuracy: 0.2748 - val_loss: 1.5539 - val_accuracy: 0.3977\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 9s 607us/step - loss: 1.5082 - accuracy: 0.3986 - val_loss: 1.5436 - val_accuracy: 0.3890\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 8s 586us/step - loss: 1.4230 - accuracy: 0.4403 - val_loss: 1.3341 - val_accuracy: 0.4757\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 8s 588us/step - loss: 1.3641 - accuracy: 0.4674 - val_loss: 1.3740 - val_accuracy: 0.5053\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 8s 594us/step - loss: 1.3288 - accuracy: 0.4936 - val_loss: 1.2929 - val_accuracy: 0.4997\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 8s 588us/step - loss: 1.2947 - accuracy: 0.4994 - val_loss: 1.3498 - val_accuracy: 0.4697\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 8s 588us/step - loss: 1.2556 - accuracy: 0.5177 - val_loss: 1.4290 - val_accuracy: 0.4810\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 8s 590us/step - loss: 1.2318 - accuracy: 0.5301 - val_loss: 1.2858 - val_accuracy: 0.5133\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 8s 590us/step - loss: 1.2142 - accuracy: 0.5351 - val_loss: 1.3182 - val_accuracy: 0.5113\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 8s 589us/step - loss: 1.1915 - accuracy: 0.5468 - val_loss: 1.2008 - val_accuracy: 0.5460\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.1614 - accuracy: 0.5586 - val_loss: 1.4337 - val_accuracy: 0.4657\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.1543 - accuracy: 0.5637 - val_loss: 1.2975 - val_accuracy: 0.5110\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.1384 - accuracy: 0.5740 - val_loss: 1.3548 - val_accuracy: 0.5180\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.1081 - accuracy: 0.5805 - val_loss: 1.1920 - val_accuracy: 0.5640\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 8s 589us/step - loss: 1.0942 - accuracy: 0.5858 - val_loss: 1.3459 - val_accuracy: 0.4937\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 8s 581us/step - loss: 1.0843 - accuracy: 0.5918 - val_loss: 1.2512 - val_accuracy: 0.5603\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.0698 - accuracy: 0.5939 - val_loss: 1.2517 - val_accuracy: 0.5240\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.0593 - accuracy: 0.6022 - val_loss: 1.1385 - val_accuracy: 0.5757\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.0441 - accuracy: 0.6049 - val_loss: 1.2435 - val_accuracy: 0.5637\n",
      "Time:  0:02:45.324762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fb9ec135748>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense():\n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "\n",
    "    flat_img = Flatten()(input_img)\n",
    "    dens_0 = Dense(1000, activation='relu')(flat_img)\n",
    "    dens_1 = Dense(512, activation='relu')(dens_0)\n",
    "    dens_2 = Dense(256, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(128, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(64, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(32, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(16, activation='relu')(dens_5)\n",
    "    dens = Dense(6, activation='softmax')(dens_6)\n",
    "  \n",
    "    \n",
    "    fc = Model(input_img, dens, name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    time_start = datetime.now()   \n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    return fc\n",
    "\n",
    "dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сеть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубокий автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 256)               69777152  \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 150, 150, 3)       69844396  \n",
      "=================================================================\n",
      "Total params: 139,621,548\n",
      "Trainable params: 139,621,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 7.2509 - accuracy: 0.3412 - val_loss: 6.8879 - val_accuracy: 0.3339\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 6.7764 - accuracy: 0.3424 - val_loss: 6.6662 - val_accuracy: 0.3822\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 6.6268 - accuracy: 0.3450 - val_loss: 6.6253 - val_accuracy: 0.3483\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 5.2079 - accuracy: 0.3432 - val_loss: 3.4839 - val_accuracy: 0.4135\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3000 - accuracy: 0.3528 - val_loss: 3.2650 - val_accuracy: 0.3955\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2457 - accuracy: 0.3550 - val_loss: 3.2579 - val_accuracy: 0.3006\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2402 - accuracy: 0.3544 - val_loss: 3.2525 - val_accuracy: 0.3866\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2382 - accuracy: 0.3542 - val_loss: 3.2509 - val_accuracy: 0.3553\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2365 - accuracy: 0.3552 - val_loss: 3.2486 - val_accuracy: 0.3609\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2287 - accuracy: 0.3553 - val_loss: 3.2305 - val_accuracy: 0.4089\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2126 - accuracy: 0.3547 - val_loss: 3.2223 - val_accuracy: 0.2885\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2027 - accuracy: 0.3527 - val_loss: 3.2039 - val_accuracy: 0.3419\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1901 - accuracy: 0.3520 - val_loss: 3.2020 - val_accuracy: 0.3535\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1821 - accuracy: 0.3511 - val_loss: 3.1936 - val_accuracy: 0.3717\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1768 - accuracy: 0.3499 - val_loss: 3.1884 - val_accuracy: 0.3732\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1746 - accuracy: 0.3495 - val_loss: 3.1860 - val_accuracy: 0.3793\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1724 - accuracy: 0.3505 - val_loss: 3.1854 - val_accuracy: 0.3065\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1726 - accuracy: 0.3485 - val_loss: 3.1827 - val_accuracy: 0.3387\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1688 - accuracy: 0.3473 - val_loss: 3.1803 - val_accuracy: 0.3848\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1684 - accuracy: 0.3492 - val_loss: 3.1815 - val_accuracy: 0.3555\n",
      "Time:  0:05:42.999426\n"
     ]
    }
   ],
   "source": [
    "def deep_au():\n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "    flat_img = Flatten()(input_img)\n",
    "\n",
    "    encoded = Dense(1024, activation='relu')(flat_img)\n",
    "    encoded = Dense(512, activation='relu')(encoded)\n",
    "    encoded = Dense(256, activation='relu')(encoded)\n",
    "    input_encoded = Input(shape=(256,))\n",
    "##########################################################################\n",
    "    decoded = Dense(512, activation='relu')(input_encoded)\n",
    "    decoded = Dense(1024, activation='relu')(decoded)\n",
    "    flat_decoded = Dense(150*150*3, activation='relu')(decoded)\n",
    "    decoded = Reshape((150, 150, 3))(flat_decoded)\n",
    "    \n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "\n",
    "    \n",
    "    autoencoder.summary()\n",
    "    \n",
    "    \n",
    "    autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    time_start = datetime.now()    \n",
    "    autoencoder.fit(train_images, train_images,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder2 = deep_au()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              69121024  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 69,777,152\n",
      "Trainable params: 69,777,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder2.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 256)               69777152  \n",
      "_________________________________________________________________\n",
      "dens_ (Model)                (None, 6)                 43862     \n",
      "=================================================================\n",
      "Total params: 69,821,014\n",
      "Trainable params: 69,821,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 595us/step - loss: 25.3691 - accuracy: 0.1827 - val_loss: 2.0544 - val_accuracy: 0.1370\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.8381 - accuracy: 0.2324 - val_loss: 1.6935 - val_accuracy: 0.2960\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.6744 - accuracy: 0.3199 - val_loss: 1.5009 - val_accuracy: 0.3947\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 8s 575us/step - loss: 1.5003 - accuracy: 0.4099 - val_loss: 1.4952 - val_accuracy: 0.4273\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.4279 - accuracy: 0.4394 - val_loss: 1.4319 - val_accuracy: 0.4140\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.3796 - accuracy: 0.4657 - val_loss: 1.2777 - val_accuracy: 0.5147\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.3414 - accuracy: 0.4809 - val_loss: 1.2568 - val_accuracy: 0.5083\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.2890 - accuracy: 0.5052 - val_loss: 1.2670 - val_accuracy: 0.5043\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 8s 575us/step - loss: 1.2614 - accuracy: 0.5143 - val_loss: 1.2433 - val_accuracy: 0.5197\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 8s 574us/step - loss: 1.2409 - accuracy: 0.5242 - val_loss: 1.2243 - val_accuracy: 0.5387\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 8s 574us/step - loss: 1.2045 - accuracy: 0.5382 - val_loss: 1.1863 - val_accuracy: 0.5467\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.1797 - accuracy: 0.5487 - val_loss: 1.1808 - val_accuracy: 0.5557\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.1667 - accuracy: 0.5537 - val_loss: 1.1642 - val_accuracy: 0.5643\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 8s 575us/step - loss: 1.1428 - accuracy: 0.5631 - val_loss: 1.1584 - val_accuracy: 0.5553\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 8s 601us/step - loss: 1.1265 - accuracy: 0.5708 - val_loss: 1.2654 - val_accuracy: 0.5353\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.1011 - accuracy: 0.5788 - val_loss: 1.2409 - val_accuracy: 0.5243\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 1.0889 - accuracy: 0.5919 - val_loss: 1.2246 - val_accuracy: 0.5390\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.0877 - accuracy: 0.5870 - val_loss: 1.1392 - val_accuracy: 0.5737\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.0753 - accuracy: 0.5966 - val_loss: 1.2186 - val_accuracy: 0.5460\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.0492 - accuracy: 0.6016 - val_loss: 1.3547 - val_accuracy: 0.4813\n",
      "Time:  0:02:43.328393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fb874191908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense2_auto(autoencoder2):\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    encoder_dim = Input(shape=(256,))\n",
    "    \n",
    "    dens_1 = Dense(128, activation='relu')(encoder_dim)\n",
    "    dens_2 = Dense(64, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(32, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(16, activation='relu')(dens_3)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_4)\n",
    "\n",
    "    \n",
    "    auto = Model(input_img, autoencoder2.layers[1](input_img), name=\"encoder\")    \n",
    "    dens_ = Model(encoder_dim, dens, name=\"dens_\")\n",
    "  \n",
    "    fc = Model(input_img, dens_(auto(input_img)), name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    time_start = datetime.now()\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    return fc\n",
    "\n",
    "dense2_auto(autoencoder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1024)              69121024  \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 69,821,014\n",
      "Trainable params: 69,821,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 594us/step - loss: 5.7940 - accuracy: 0.1839 - val_loss: 1.7736 - val_accuracy: 0.2513\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.7496 - accuracy: 0.2721 - val_loss: 1.6224 - val_accuracy: 0.2977\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.4756 - accuracy: 0.4116 - val_loss: 1.7200 - val_accuracy: 0.3147\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.4190 - accuracy: 0.4343 - val_loss: 1.4509 - val_accuracy: 0.4393\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.3672 - accuracy: 0.4648 - val_loss: 1.5602 - val_accuracy: 0.4067\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.3276 - accuracy: 0.4887 - val_loss: 1.3713 - val_accuracy: 0.4560\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.2819 - accuracy: 0.5132 - val_loss: 1.3532 - val_accuracy: 0.5047\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.2568 - accuracy: 0.5234 - val_loss: 1.2839 - val_accuracy: 0.5107\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 1.2292 - accuracy: 0.5283 - val_loss: 1.3449 - val_accuracy: 0.5023\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 8s 585us/step - loss: 1.1975 - accuracy: 0.5461 - val_loss: 1.1957 - val_accuracy: 0.5503\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.1811 - accuracy: 0.5539 - val_loss: 1.2633 - val_accuracy: 0.5203\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.1550 - accuracy: 0.5612 - val_loss: 1.2641 - val_accuracy: 0.5190\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.1307 - accuracy: 0.5713 - val_loss: 1.2980 - val_accuracy: 0.5217\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.1131 - accuracy: 0.5810 - val_loss: 1.1485 - val_accuracy: 0.5697\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.1067 - accuracy: 0.5821 - val_loss: 1.1811 - val_accuracy: 0.5660\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.0921 - accuracy: 0.5877 - val_loss: 1.2261 - val_accuracy: 0.5393\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.0679 - accuracy: 0.5956 - val_loss: 1.1268 - val_accuracy: 0.5857\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.0475 - accuracy: 0.6004 - val_loss: 1.1730 - val_accuracy: 0.5637\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 8s 575us/step - loss: 1.0411 - accuracy: 0.6063 - val_loss: 1.2779 - val_accuracy: 0.5590\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.0273 - accuracy: 0.6122 - val_loss: 1.4079 - val_accuracy: 0.5173\n",
      "Time:  0:02:43.136844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fb8643184a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense2():\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    flat_img = Flatten()(input_img)\n",
    "    \n",
    "    dens_1 = Dense(1024, activation='relu')(flat_img)\n",
    "    dens_2 = Dense(512, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(256, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(128, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(64, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(32, activation='relu')(dens_5)\n",
    "    dens_7 = Dense(16, activation='relu')(dens_6)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_7)\n",
    "  \n",
    "    fc = Model(input_img, dens, name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    time_start = datetime.now()\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    return fc\n",
    "\n",
    "dense2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сеть 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверточный автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 19, 19, 8)\n",
      "(None, 150, 150, 3)\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 19, 19, 8)         6680      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 150, 150, 3)       7259      \n",
      "=================================================================\n",
      "Total params: 13,939\n",
      "Trainable params: 13,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 24s 2ms/step - loss: 1.5915 - accuracy: 0.4550 - val_loss: 1.4683 - val_accuracy: 0.4178\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4589 - accuracy: 0.5702 - val_loss: 1.4646 - val_accuracy: 0.4438\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4565 - accuracy: 0.6167 - val_loss: 1.4607 - val_accuracy: 0.6414\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4548 - accuracy: 0.6849 - val_loss: 1.4601 - val_accuracy: 0.6841\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4539 - accuracy: 0.7020 - val_loss: 1.4605 - val_accuracy: 0.7398\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4533 - accuracy: 0.7097 - val_loss: 1.4591 - val_accuracy: 0.7191\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4530 - accuracy: 0.7223 - val_loss: 1.4585 - val_accuracy: 0.7694\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4527 - accuracy: 0.7272 - val_loss: 1.4593 - val_accuracy: 0.6766\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4526 - accuracy: 0.7290 - val_loss: 1.4585 - val_accuracy: 0.6942\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4523 - accuracy: 0.7368 - val_loss: 1.4611 - val_accuracy: 0.6829\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4522 - accuracy: 0.7361 - val_loss: 1.4587 - val_accuracy: 0.7601\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4521 - accuracy: 0.7463 - val_loss: 1.4603 - val_accuracy: 0.6542\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4520 - accuracy: 0.7426 - val_loss: 1.4587 - val_accuracy: 0.6721\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4519 - accuracy: 0.7444 - val_loss: 1.4582 - val_accuracy: 0.7467\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4518 - accuracy: 0.7503 - val_loss: 1.4583 - val_accuracy: 0.7287\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4517 - accuracy: 0.7528 - val_loss: 1.4578 - val_accuracy: 0.7926\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4516 - accuracy: 0.7530 - val_loss: 1.4575 - val_accuracy: 0.7577\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4516 - accuracy: 0.7560 - val_loss: 1.4585 - val_accuracy: 0.7444\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4515 - accuracy: 0.7575 - val_loss: 1.4575 - val_accuracy: 0.7518\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 20s 1ms/step - loss: 1.4515 - accuracy: 0.7628 - val_loss: 1.4577 - val_accuracy: 0.7310\n",
      "Time:  0:06:46.842823\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "def conv_ae():    \n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "    #flat_img = Flatten()(input_img)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(encoded.shape)\n",
    "    input_encoded = Input(shape=(19, 19, 8))\n",
    "##############################################################\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(input_encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='relu')(x)\n",
    "    print(decoded.shape)\n",
    "    \n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    \n",
    "    autoencoder.summary()\n",
    "    \n",
    "    \n",
    "    autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    time_start = datetime.now()\n",
    "    autoencoder.fit(train_images, train_images,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder3 = conv_ae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 38, 38, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 19, 19, 8)         0         \n",
      "=================================================================\n",
      "Total params: 6,680\n",
      "Trainable params: 6,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder3.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 19, 19, 8)         6680      \n",
      "_________________________________________________________________\n",
      "dens_ (Model)                (None, 6)                 3658326   \n",
      "=================================================================\n",
      "Total params: 3,665,006\n",
      "Trainable params: 3,665,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 9s 665us/step - loss: 1.3889 - accuracy: 0.4440 - val_loss: 1.0791 - val_accuracy: 0.5780\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 9s 636us/step - loss: 1.0220 - accuracy: 0.6109 - val_loss: 1.0531 - val_accuracy: 0.6057\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.8835 - accuracy: 0.6760 - val_loss: 1.0810 - val_accuracy: 0.6047\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 9s 636us/step - loss: 0.7883 - accuracy: 0.7131 - val_loss: 0.8311 - val_accuracy: 0.7113\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.7010 - accuracy: 0.7495 - val_loss: 0.7053 - val_accuracy: 0.7617\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 9s 637us/step - loss: 0.6247 - accuracy: 0.7743 - val_loss: 0.8283 - val_accuracy: 0.7027\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 9s 640us/step - loss: 0.5407 - accuracy: 0.8089 - val_loss: 0.7130 - val_accuracy: 0.7420\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 9s 635us/step - loss: 0.4754 - accuracy: 0.8378 - val_loss: 1.1755 - val_accuracy: 0.6877\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 9s 635us/step - loss: 0.4120 - accuracy: 0.8577 - val_loss: 0.8044 - val_accuracy: 0.7607\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 9s 639us/step - loss: 0.3442 - accuracy: 0.8821 - val_loss: 0.7000 - val_accuracy: 0.7937\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 9s 635us/step - loss: 0.2988 - accuracy: 0.9010 - val_loss: 0.9135 - val_accuracy: 0.7420\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 9s 637us/step - loss: 0.2475 - accuracy: 0.9199 - val_loss: 0.9266 - val_accuracy: 0.7893\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.1999 - accuracy: 0.9342 - val_loss: 1.2916 - val_accuracy: 0.7083\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 9s 647us/step - loss: 0.1896 - accuracy: 0.9398 - val_loss: 0.9776 - val_accuracy: 0.7780\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 9s 640us/step - loss: 0.1552 - accuracy: 0.9538 - val_loss: 1.0476 - val_accuracy: 0.7573\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.1367 - accuracy: 0.9585 - val_loss: 0.9439 - val_accuracy: 0.7750\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 9s 636us/step - loss: 0.1119 - accuracy: 0.9673 - val_loss: 1.3435 - val_accuracy: 0.7503\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 9s 637us/step - loss: 0.1046 - accuracy: 0.9710 - val_loss: 1.9508 - val_accuracy: 0.6913\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 9s 637us/step - loss: 0.1444 - accuracy: 0.9633 - val_loss: 0.8596 - val_accuracy: 0.7640\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 9s 637us/step - loss: 0.0861 - accuracy: 0.9786 - val_loss: 1.5270 - val_accuracy: 0.7283\n",
      "Time:  0:03:00.428092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fb47e465a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense3_auto(autoencoder3):\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    \n",
    "    encoder_dim = Input(shape=(19, 19, 8))\n",
    "    flat_encoder_dim = Flatten()(encoder_dim)\n",
    "    \n",
    "    dens_1 = Dense(1024, activation='relu')(flat_encoder_dim)\n",
    "    dens_2 = Dense(512, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(256, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(128, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(64, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(32, activation='relu')(dens_5)\n",
    "    dens_7 = Dense(16, activation='relu')(dens_6)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_7)\n",
    "\n",
    "    auto = Model(input_img, autoencoder3.layers[1](input_img), name=\"encoder\")    \n",
    "    dens_ = Model(encoder_dim, dens, name=\"dens_\")\n",
    "    \n",
    "    fc = Model(input_img, dens_(auto(input_img)), name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    time_start = datetime.now()\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    return fc\n",
    "\n",
    "dense3_auto(autoencoder3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 19, 19, 8)\n",
      "(None, None)\n",
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 75, 75, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 38, 38, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 19, 19, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2888)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1024)              2958336   \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 3,665,006\n",
      "Trainable params: 3,665,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 9s 661us/step - loss: 1.6546 - accuracy: 0.3102 - val_loss: 1.2840 - val_accuracy: 0.4923\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 9s 640us/step - loss: 1.1421 - accuracy: 0.5557 - val_loss: 1.1074 - val_accuracy: 0.5893\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 9s 640us/step - loss: 0.9453 - accuracy: 0.6492 - val_loss: 0.9053 - val_accuracy: 0.6703\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 9s 636us/step - loss: 0.8213 - accuracy: 0.7005 - val_loss: 0.8123 - val_accuracy: 0.7167\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.7193 - accuracy: 0.7381 - val_loss: 0.8226 - val_accuracy: 0.7070\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.6398 - accuracy: 0.7745 - val_loss: 0.7381 - val_accuracy: 0.7533\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.5421 - accuracy: 0.8068 - val_loss: 0.9757 - val_accuracy: 0.7087\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 9s 639us/step - loss: 0.4506 - accuracy: 0.8426 - val_loss: 0.7296 - val_accuracy: 0.7547\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.3504 - accuracy: 0.8773 - val_loss: 0.9443 - val_accuracy: 0.7137\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.2917 - accuracy: 0.9018 - val_loss: 1.0121 - val_accuracy: 0.7473\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 9s 643us/step - loss: 0.2405 - accuracy: 0.9253 - val_loss: 1.3593 - val_accuracy: 0.6493\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 9s 660us/step - loss: 0.1828 - accuracy: 0.9439 - val_loss: 1.1632 - val_accuracy: 0.7533\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 9s 646us/step - loss: 0.1365 - accuracy: 0.9584 - val_loss: 1.4339 - val_accuracy: 0.7190\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 9s 640us/step - loss: 0.1530 - accuracy: 0.9597 - val_loss: 1.3286 - val_accuracy: 0.7510\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 9s 639us/step - loss: 0.1104 - accuracy: 0.9692 - val_loss: 1.3607 - val_accuracy: 0.7267\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 9s 639us/step - loss: 0.1086 - accuracy: 0.9705 - val_loss: 1.7975 - val_accuracy: 0.7367\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 9s 638us/step - loss: 0.1148 - accuracy: 0.9729 - val_loss: 1.3398 - val_accuracy: 0.7140\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 9s 639us/step - loss: 0.0833 - accuracy: 0.9782 - val_loss: 2.0578 - val_accuracy: 0.7260\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 9s 639us/step - loss: 0.1036 - accuracy: 0.9766 - val_loss: 1.6008 - val_accuracy: 0.7400\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 9s 644us/step - loss: 0.1065 - accuracy: 0.9756 - val_loss: 1.6159 - val_accuracy: 0.7497\n",
      "Time:  0:03:01.002814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fb47e0e7898>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense3():\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "  \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    print(x.shape)\n",
    "    dens_1 = Dense(1024, activation='relu')(x)\n",
    "    dens_2 = Dense(512, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(256, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(128, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(64, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(32, activation='relu')(dens_5)\n",
    "    dens_7 = Dense(16, activation='relu')(dens_6)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_7)\n",
    "\n",
    "    \n",
    "    fc = Model(input_img, dens, name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    time_start = datetime.now()\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "    print('Time: ', datetime.now() - time_start)\n",
    "    return fc\n",
    "\n",
    "dense3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
