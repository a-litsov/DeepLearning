{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH = 128\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "train_data = datagen.flow_from_directory('/kaggle/input/intel-image-classification/seg_train/seg_train/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=14034,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "test_data = datagen.flow_from_directory('/kaggle/input/intel-image-classification/seg_test/seg_test/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=3000,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "\n",
    "#train_images, train_labels = train_data.next()\n",
    "#test_images, test_labels = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = train_data.next()\n",
    "test_images, test_labels = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14034, 150, 150, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = np.reshape( train_images,  (len(train_images),  150 ,  150 ,  3 ))   # adapt this if using `channels_first` image data format\n",
    "#test_images =  np.reshape( test_images,  (len(test_images),  150 ,  150 ,  3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сеть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простой автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "def create_dense_ae():\n",
    "    \n",
    "    encoding_dim = 1000\n",
    "\n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "    flat_img = Flatten()(input_img)\n",
    "\n",
    "    encoded = Dense(encoding_dim, activation='relu')(flat_img)\n",
    "    \n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    flat_decoded = Dense(150*150*3, activation='relu')(input_encoded)\n",
    "    decoded = Reshape((150, 150, 3))(flat_decoded)\n",
    "\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1000)              67501000  \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 150, 150, 3)       67567500  \n",
      "=================================================================\n",
      "Total params: 135,068,500\n",
      "Trainable params: 135,068,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 7.1449 - accuracy: 0.3530 - val_loss: 6.9351 - val_accuracy: 0.3892\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 6.6551 - accuracy: 0.3968 - val_loss: 6.3979 - val_accuracy: 0.3648\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 4.7238 - accuracy: 0.4462 - val_loss: 4.4172 - val_accuracy: 0.4173\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 4.0171 - accuracy: 0.4993 - val_loss: 3.9381 - val_accuracy: 0.5465\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.6696 - accuracy: 0.5453 - val_loss: 3.5695 - val_accuracy: 0.5285\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.3419 - accuracy: 0.5636 - val_loss: 3.3308 - val_accuracy: 0.5541\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2825 - accuracy: 0.5783 - val_loss: 3.2775 - val_accuracy: 0.6162\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2618 - accuracy: 0.5891 - val_loss: 3.2733 - val_accuracy: 0.5234\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2554 - accuracy: 0.5964 - val_loss: 3.2630 - val_accuracy: 0.5390\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2466 - accuracy: 0.6000 - val_loss: 3.2541 - val_accuracy: 0.5846\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2367 - accuracy: 0.6073 - val_loss: 3.2460 - val_accuracy: 0.6291\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2295 - accuracy: 0.6086 - val_loss: 3.2398 - val_accuracy: 0.6306\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2210 - accuracy: 0.6116 - val_loss: 3.2287 - val_accuracy: 0.6260\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2121 - accuracy: 0.6166 - val_loss: 3.2240 - val_accuracy: 0.5778\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2050 - accuracy: 0.6188 - val_loss: 3.2157 - val_accuracy: 0.5734\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.2011 - accuracy: 0.6224 - val_loss: 3.2132 - val_accuracy: 0.6351\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1941 - accuracy: 0.6244 - val_loss: 3.2009 - val_accuracy: 0.5959\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1854 - accuracy: 0.6224 - val_loss: 3.1977 - val_accuracy: 0.5977\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1815 - accuracy: 0.6273 - val_loss: 3.1902 - val_accuracy: 0.6412\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 3.1717 - accuracy: 0.6309 - val_loss: 3.1818 - val_accuracy: 0.5906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe18811ff28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder, autoencoder = create_dense_ae()\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "autoencoder.fit( train_images, train_images, epochs= 20, batch_size= 128, shuffle= True, \n",
    "                validation_data= (test_images,  test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              67501000  \n",
      "=================================================================\n",
      "Total params: 67,501,000\n",
      "Trainable params: 67,501,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1000)              67501000  \n",
      "_________________________________________________________________\n",
      "dens_ (Model)                (None, 6)                 687702    \n",
      "=================================================================\n",
      "Total params: 68,188,702\n",
      "Trainable params: 68,188,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 600us/step - loss: 6.5697 - accuracy: 0.2533 - val_loss: 1.8243 - val_accuracy: 0.3157\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 8s 587us/step - loss: 1.5972 - accuracy: 0.3849 - val_loss: 1.4534 - val_accuracy: 0.4313\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 8s 583us/step - loss: 1.3299 - accuracy: 0.4942 - val_loss: 1.2887 - val_accuracy: 0.5130\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.2262 - accuracy: 0.5366 - val_loss: 1.1978 - val_accuracy: 0.5553\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.1796 - accuracy: 0.5547 - val_loss: 1.2371 - val_accuracy: 0.5163\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.1456 - accuracy: 0.5668 - val_loss: 1.1067 - val_accuracy: 0.5753\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 9s 609us/step - loss: 1.1018 - accuracy: 0.5807 - val_loss: 1.2055 - val_accuracy: 0.5547\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.0853 - accuracy: 0.5930 - val_loss: 1.3215 - val_accuracy: 0.5233\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.0578 - accuracy: 0.6047 - val_loss: 1.1220 - val_accuracy: 0.5843\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.0432 - accuracy: 0.6100 - val_loss: 1.1767 - val_accuracy: 0.5697\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.0165 - accuracy: 0.6164 - val_loss: 1.1056 - val_accuracy: 0.5840\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.0036 - accuracy: 0.6249 - val_loss: 1.1773 - val_accuracy: 0.5667\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 0.9865 - accuracy: 0.6307 - val_loss: 1.1478 - val_accuracy: 0.5847\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 8s 581us/step - loss: 0.9635 - accuracy: 0.6394 - val_loss: 1.1454 - val_accuracy: 0.5753\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 8s 583us/step - loss: 0.9420 - accuracy: 0.6484 - val_loss: 1.1425 - val_accuracy: 0.5897\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 0.9342 - accuracy: 0.6503 - val_loss: 1.2428 - val_accuracy: 0.5430\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 8s 581us/step - loss: 0.9142 - accuracy: 0.6578 - val_loss: 1.0950 - val_accuracy: 0.6033\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 0.8961 - accuracy: 0.6630 - val_loss: 1.2243 - val_accuracy: 0.5703\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 0.8861 - accuracy: 0.6678 - val_loss: 1.2395 - val_accuracy: 0.5670\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 0.8625 - accuracy: 0.6731 - val_loss: 1.2213 - val_accuracy: 0.5910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fe18806bdd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense_auto(autoencoder):\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    encoder_dim = Input(shape=(1000,))\n",
    "    \n",
    "    dens_1 = Dense(512, activation='relu')(encoder_dim)\n",
    "    dens_2 = Dense(256, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(128, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(64, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(32, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(16, activation='relu')(dens_5)\n",
    "    dens = Dense(6, activation='softmax')(dens_6)\n",
    "\n",
    "    \n",
    "    auto = Model(input_img, autoencoder.layers[1](input_img), name=\"encoder\")    \n",
    "    dens_ = Model(encoder_dim, dens, name=\"dens_\")\n",
    "    fc = Model(input_img, dens_(auto(input_img)), name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "\n",
    "    return fc\n",
    "\n",
    "dense_auto(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              67501000  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 68,188,702\n",
      "Trainable params: 68,188,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 592us/step - loss: 4.8278 - accuracy: 0.1801 - val_loss: 1.7909 - val_accuracy: 0.1750\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 8s 574us/step - loss: 1.7911 - accuracy: 0.1790 - val_loss: 1.7905 - val_accuracy: 0.1750\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 8s 575us/step - loss: 1.7909 - accuracy: 0.1790 - val_loss: 1.7903 - val_accuracy: 0.1750\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 8s 574us/step - loss: 1.7909 - accuracy: 0.1790 - val_loss: 1.7903 - val_accuracy: 0.1750\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 8s 576us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 8s 575us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 8s 577us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 8s 584us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 8s 583us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 8s 583us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 8s 580us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 8s 581us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 8s 578us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 8s 579us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 8s 582us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7902 - val_accuracy: 0.1750\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 8s 588us/step - loss: 1.7908 - accuracy: 0.1790 - val_loss: 1.7901 - val_accuracy: 0.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fe002308400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense():\n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "\n",
    "    flat_img = Flatten()(input_img)\n",
    "    dens_0 = Dense(1000, activation='relu')(flat_img)\n",
    "    dens_1 = Dense(512, activation='relu')(dens_0)\n",
    "    dens_2 = Dense(256, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(128, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(64, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(32, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(16, activation='relu')(dens_5)\n",
    "    dens = Dense(6, activation='softmax')(dens_6)\n",
    "  \n",
    "    \n",
    "    fc = Model(input_img, dens, name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "\n",
    "    return fc\n",
    "\n",
    "dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сеть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубокий автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 256)               69777152  \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 150, 150, 3)       69844396  \n",
      "=================================================================\n",
      "Total params: 139,621,548\n",
      "Trainable params: 139,621,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 7.2561 - accuracy: 0.3403 - val_loss: 6.9083 - val_accuracy: 0.3652\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 6.7661 - accuracy: 0.3429 - val_loss: 6.6810 - val_accuracy: 0.3772\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 6.6490 - accuracy: 0.3460 - val_loss: 6.6749 - val_accuracy: 0.3705\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 6.6469 - accuracy: 0.3463 - val_loss: 6.6721 - val_accuracy: 0.3706\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 6.6382 - accuracy: 0.3482 - val_loss: 6.6220 - val_accuracy: 0.3563\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 6.5631 - accuracy: 0.3473 - val_loss: 6.5646 - val_accuracy: 0.3426\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 6.4969 - accuracy: 0.3461 - val_loss: 6.5057 - val_accuracy: 0.3445\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 6.4775 - accuracy: 0.3476 - val_loss: 6.5028 - val_accuracy: 0.2915\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 6.4558 - accuracy: 0.3472 - val_loss: 6.4618 - val_accuracy: 0.3891\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 6.4276 - accuracy: 0.3469 - val_loss: 6.4468 - val_accuracy: 0.3768\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 4.9575 - accuracy: 0.3458 - val_loss: 3.3509 - val_accuracy: 0.3512\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 2.9527 - accuracy: 0.3495 - val_loss: 2.8135 - val_accuracy: 0.3625\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 2.7999 - accuracy: 0.3567 - val_loss: 2.8111 - val_accuracy: 0.3258\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 2.7906 - accuracy: 0.3581 - val_loss: 2.8013 - val_accuracy: 0.3591\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 2.7857 - accuracy: 0.3550 - val_loss: 2.7947 - val_accuracy: 0.3583\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 2.7718 - accuracy: 0.3575 - val_loss: 2.7732 - val_accuracy: 0.2686\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 2.7637 - accuracy: 0.3536 - val_loss: 2.7749 - val_accuracy: 0.3216\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 2.7643 - accuracy: 0.3523 - val_loss: 2.7757 - val_accuracy: 0.3662\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 17s 1ms/step - loss: 2.7638 - accuracy: 0.3530 - val_loss: 2.7751 - val_accuracy: 0.3771\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 15s 1ms/step - loss: 2.7639 - accuracy: 0.3513 - val_loss: 2.7751 - val_accuracy: 0.3186\n"
     ]
    }
   ],
   "source": [
    "def deep_au():\n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "    flat_img = Flatten()(input_img)\n",
    "\n",
    "    encoded = Dense(1024, activation='relu')(flat_img)\n",
    "    encoded = Dense(512, activation='relu')(encoded)\n",
    "    encoded = Dense(256, activation='relu')(encoded)\n",
    "    input_encoded = Input(shape=(256,))\n",
    "##########################################################################\n",
    "    decoded = Dense(512, activation='relu')(input_encoded)\n",
    "    decoded = Dense(1024, activation='relu')(decoded)\n",
    "    flat_decoded = Dense(150*150*3, activation='relu')(decoded)\n",
    "    decoded = Reshape((150, 150, 3))(flat_decoded)\n",
    "    \n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "\n",
    "    \n",
    "    autoencoder.summary()\n",
    "    \n",
    "    \n",
    "    autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    autoencoder.fit(train_images, train_images,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder2 = deep_au()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              69121024  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 69,777,152\n",
      "Trainable params: 69,777,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder2.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 256)               69777152  \n",
      "_________________________________________________________________\n",
      "dens_ (Model)                (None, 6)                 43862     \n",
      "=================================================================\n",
      "Total params: 69,821,014\n",
      "Trainable params: 69,821,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 5s 361us/step - loss: 11.1699 - accuracy: 0.1973 - val_loss: 1.7398 - val_accuracy: 0.2583\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 5s 344us/step - loss: 1.7157 - accuracy: 0.3107 - val_loss: 1.5371 - val_accuracy: 0.3930\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 5s 366us/step - loss: 1.5114 - accuracy: 0.3989 - val_loss: 1.4674 - val_accuracy: 0.3903\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 5s 345us/step - loss: 1.4424 - accuracy: 0.4329 - val_loss: 1.5360 - val_accuracy: 0.4113\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 5s 345us/step - loss: 1.3835 - accuracy: 0.4620 - val_loss: 1.4598 - val_accuracy: 0.4503\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 5s 344us/step - loss: 1.3504 - accuracy: 0.4743 - val_loss: 1.3147 - val_accuracy: 0.4983\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 5s 347us/step - loss: 1.3080 - accuracy: 0.4924 - val_loss: 1.6070 - val_accuracy: 0.4040\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 5s 345us/step - loss: 1.2723 - accuracy: 0.5104 - val_loss: 1.2578 - val_accuracy: 0.5190\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 5s 346us/step - loss: 1.2276 - accuracy: 0.5287 - val_loss: 1.2521 - val_accuracy: 0.5287\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 5s 344us/step - loss: 1.1999 - accuracy: 0.5451 - val_loss: 1.3080 - val_accuracy: 0.5200\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 5s 346us/step - loss: 1.1921 - accuracy: 0.5472 - val_loss: 1.2924 - val_accuracy: 0.5013\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 5s 344us/step - loss: 1.1678 - accuracy: 0.5556 - val_loss: 1.1728 - val_accuracy: 0.5437\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 5s 345us/step - loss: 1.1430 - accuracy: 0.5654 - val_loss: 1.3126 - val_accuracy: 0.5207\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 5s 347us/step - loss: 1.1304 - accuracy: 0.5706 - val_loss: 1.4694 - val_accuracy: 0.4537\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 5s 349us/step - loss: 1.1188 - accuracy: 0.5742 - val_loss: 1.1711 - val_accuracy: 0.5447\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 5s 347us/step - loss: 1.0927 - accuracy: 0.5844 - val_loss: 1.2562 - val_accuracy: 0.5193\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 5s 347us/step - loss: 1.0793 - accuracy: 0.5906 - val_loss: 1.2018 - val_accuracy: 0.5503\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 5s 346us/step - loss: 1.0675 - accuracy: 0.6005 - val_loss: 1.2784 - val_accuracy: 0.5387\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 5s 347us/step - loss: 1.0619 - accuracy: 0.6030 - val_loss: 1.1188 - val_accuracy: 0.5747\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 5s 348us/step - loss: 1.0425 - accuracy: 0.6031 - val_loss: 1.2495 - val_accuracy: 0.5547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fdfec22f4a8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense2_auto(autoencoder2):\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    encoder_dim = Input(shape=(256,))\n",
    "    \n",
    "    dens_1 = Dense(128, activation='relu')(encoder_dim)\n",
    "    dens_2 = Dense(64, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(32, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(16, activation='relu')(dens_3)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_4)\n",
    "\n",
    "    \n",
    "    auto = Model(input_img, autoencoder2.layers[1](input_img), name=\"encoder\")    \n",
    "    dens_ = Model(encoder_dim, dens, name=\"dens_\")\n",
    "  \n",
    "    fc = Model(input_img, dens_(auto(input_img)), name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "\n",
    "    return fc\n",
    "\n",
    "dense2_auto(autoencoder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1024)              69121024  \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 69,821,014\n",
      "Trainable params: 69,821,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 7s 464us/step - loss: 7.7565 - accuracy: 0.1883 - val_loss: 1.8050 - val_accuracy: 0.1737\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 6s 448us/step - loss: 1.7166 - accuracy: 0.2959 - val_loss: 1.6594 - val_accuracy: 0.3207\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 6s 450us/step - loss: 1.4721 - accuracy: 0.4144 - val_loss: 1.5114 - val_accuracy: 0.3507\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 6s 448us/step - loss: 1.4013 - accuracy: 0.4470 - val_loss: 1.4705 - val_accuracy: 0.4337\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 6s 448us/step - loss: 1.3771 - accuracy: 0.4702 - val_loss: 1.6007 - val_accuracy: 0.3567\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 6s 449us/step - loss: 1.3193 - accuracy: 0.4834 - val_loss: 1.3609 - val_accuracy: 0.4657\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 6s 448us/step - loss: 1.2979 - accuracy: 0.5031 - val_loss: 1.5044 - val_accuracy: 0.4617\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 6s 449us/step - loss: 1.2616 - accuracy: 0.5126 - val_loss: 1.2890 - val_accuracy: 0.5103\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 6s 452us/step - loss: 1.2280 - accuracy: 0.5266 - val_loss: 1.3312 - val_accuracy: 0.4727\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 6s 448us/step - loss: 1.1966 - accuracy: 0.5409 - val_loss: 1.2274 - val_accuracy: 0.5350\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 6s 447us/step - loss: 1.1761 - accuracy: 0.5502 - val_loss: 1.2227 - val_accuracy: 0.5287\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 6s 449us/step - loss: 1.1653 - accuracy: 0.5523 - val_loss: 1.2060 - val_accuracy: 0.5627\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 6s 448us/step - loss: 1.1400 - accuracy: 0.5626 - val_loss: 1.1617 - val_accuracy: 0.5623\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 6s 449us/step - loss: 1.1359 - accuracy: 0.5629 - val_loss: 1.2558 - val_accuracy: 0.5160\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 6s 455us/step - loss: 1.1232 - accuracy: 0.5701 - val_loss: 1.2049 - val_accuracy: 0.5417\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 6s 452us/step - loss: 1.1006 - accuracy: 0.5796 - val_loss: 1.2115 - val_accuracy: 0.5430\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 6s 449us/step - loss: 1.0960 - accuracy: 0.5825 - val_loss: 1.7014 - val_accuracy: 0.4003\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 6s 450us/step - loss: 1.0842 - accuracy: 0.5879 - val_loss: 1.1554 - val_accuracy: 0.5603\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 6s 451us/step - loss: 1.0574 - accuracy: 0.5980 - val_loss: 1.1560 - val_accuracy: 0.5707\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 6s 449us/step - loss: 1.0397 - accuracy: 0.6057 - val_loss: 1.1989 - val_accuracy: 0.5603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fdc1c6bde80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense2():\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    flat_img = Flatten()(input_img)\n",
    "    \n",
    "    dens_1 = Dense(1024, activation='relu')(flat_img)\n",
    "    dens_2 = Dense(512, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(256, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(128, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(64, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(32, activation='relu')(dens_5)\n",
    "    dens_7 = Dense(16, activation='relu')(dens_6)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_7)\n",
    "  \n",
    "    fc = Model(input_img, dens, name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "\n",
    "    return fc\n",
    "\n",
    "dense2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сеть 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверточный автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 19, 19, 8)\n",
      "(None, 150, 150, 3)\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 19, 19, 8)         6680      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 150, 150, 3)       7259      \n",
      "=================================================================\n",
      "Total params: 13,939\n",
      "Trainable params: 13,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 22s 2ms/step - loss: 1.5835 - accuracy: 0.2944 - val_loss: 1.4751 - val_accuracy: 0.6080\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4651 - accuracy: 0.5313 - val_loss: 1.4632 - val_accuracy: 0.4933\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4574 - accuracy: 0.5997 - val_loss: 1.4635 - val_accuracy: 0.5600\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4553 - accuracy: 0.6565 - val_loss: 1.4609 - val_accuracy: 0.6569\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 19s 1ms/step - loss: 1.4544 - accuracy: 0.6778 - val_loss: 1.4605 - val_accuracy: 0.6946\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4537 - accuracy: 0.6896 - val_loss: 1.4635 - val_accuracy: 0.6204\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4533 - accuracy: 0.7016 - val_loss: 1.4612 - val_accuracy: 0.6912\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4530 - accuracy: 0.7092 - val_loss: 1.4612 - val_accuracy: 0.6699\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4528 - accuracy: 0.7124 - val_loss: 1.4587 - val_accuracy: 0.7170\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4526 - accuracy: 0.7231 - val_loss: 1.4588 - val_accuracy: 0.7771\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4525 - accuracy: 0.7234 - val_loss: 1.4597 - val_accuracy: 0.6846\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4523 - accuracy: 0.7284 - val_loss: 1.4598 - val_accuracy: 0.6945\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4523 - accuracy: 0.7304 - val_loss: 1.4581 - val_accuracy: 0.7276\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4520 - accuracy: 0.7380 - val_loss: 1.4586 - val_accuracy: 0.6665\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4520 - accuracy: 0.7398 - val_loss: 1.4576 - val_accuracy: 0.7665\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4519 - accuracy: 0.7459 - val_loss: 1.4592 - val_accuracy: 0.7085\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4519 - accuracy: 0.7465 - val_loss: 1.4577 - val_accuracy: 0.7478\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4518 - accuracy: 0.7454 - val_loss: 1.4590 - val_accuracy: 0.7355\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4517 - accuracy: 0.7491 - val_loss: 1.4577 - val_accuracy: 0.7459\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 18s 1ms/step - loss: 1.4517 - accuracy: 0.7493 - val_loss: 1.4574 - val_accuracy: 0.7473\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "def conv_ae():    \n",
    "    input_img = Input(shape=(150, 150, 3))\n",
    "    #flat_img = Flatten()(input_img)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(encoded.shape)\n",
    "    input_encoded = Input(shape=(19, 19, 8))\n",
    "##############################################################\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(input_encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='relu')(x)\n",
    "    print(decoded.shape)\n",
    "    \n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    \n",
    "    autoencoder.summary()\n",
    "    \n",
    "    \n",
    "    autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    autoencoder.fit(train_images, train_images,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images))\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder3 = conv_ae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 38, 38, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 19, 19, 8)         0         \n",
      "=================================================================\n",
      "Total params: 6,680\n",
      "Trainable params: 6,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder3.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 19, 19, 8)         6680      \n",
      "_________________________________________________________________\n",
      "dens_ (Model)                (None, 6)                 3658326   \n",
      "=================================================================\n",
      "Total params: 3,665,006\n",
      "Trainable params: 3,665,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 548us/step - loss: 1.3457 - accuracy: 0.4716 - val_loss: 1.0412 - val_accuracy: 0.6123\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 7s 507us/step - loss: 1.0167 - accuracy: 0.6160 - val_loss: 1.1995 - val_accuracy: 0.5817\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 7s 519us/step - loss: 0.8924 - accuracy: 0.6726 - val_loss: 0.9062 - val_accuracy: 0.6623\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 7s 500us/step - loss: 0.7787 - accuracy: 0.7146 - val_loss: 0.8003 - val_accuracy: 0.7023\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 7s 502us/step - loss: 0.6927 - accuracy: 0.7504 - val_loss: 0.9874 - val_accuracy: 0.6613\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 7s 498us/step - loss: 0.6151 - accuracy: 0.7763 - val_loss: 1.0172 - val_accuracy: 0.6567\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 7s 499us/step - loss: 0.5384 - accuracy: 0.8088 - val_loss: 0.8244 - val_accuracy: 0.7397\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 7s 499us/step - loss: 0.4509 - accuracy: 0.8409 - val_loss: 0.7209 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 7s 500us/step - loss: 0.3692 - accuracy: 0.8711 - val_loss: 1.1905 - val_accuracy: 0.6743\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 7s 502us/step - loss: 0.3070 - accuracy: 0.8970 - val_loss: 0.9168 - val_accuracy: 0.7450\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 7s 505us/step - loss: 0.2717 - accuracy: 0.9107 - val_loss: 0.9710 - val_accuracy: 0.7357\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 7s 505us/step - loss: 0.2057 - accuracy: 0.9322 - val_loss: 1.1424 - val_accuracy: 0.7503\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 7s 502us/step - loss: 0.1698 - accuracy: 0.9457 - val_loss: 1.1521 - val_accuracy: 0.7530\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 7s 501us/step - loss: 0.1730 - accuracy: 0.9513 - val_loss: 1.2398 - val_accuracy: 0.7340\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 7s 501us/step - loss: 0.1314 - accuracy: 0.9600 - val_loss: 1.2976 - val_accuracy: 0.7423\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 7s 500us/step - loss: 0.1026 - accuracy: 0.9714 - val_loss: 1.4355 - val_accuracy: 0.7707\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 7s 498us/step - loss: 0.1009 - accuracy: 0.9705 - val_loss: 1.4577 - val_accuracy: 0.7563\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 7s 499us/step - loss: 0.1015 - accuracy: 0.9724 - val_loss: 1.4408 - val_accuracy: 0.6847\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 7s 498us/step - loss: 0.0790 - accuracy: 0.9800 - val_loss: 1.4980 - val_accuracy: 0.7510\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 7s 498us/step - loss: 0.0849 - accuracy: 0.9774 - val_loss: 1.3914 - val_accuracy: 0.7457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fdc1c126588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense3_auto(autoencoder3):\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "    \n",
    "    encoder_dim = Input(shape=(19, 19, 8))\n",
    "    flat_encoder_dim = Flatten()(encoder_dim)\n",
    "    \n",
    "    dens_1 = Dense(1024, activation='relu')(flat_encoder_dim)\n",
    "    dens_2 = Dense(512, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(256, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(128, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(64, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(32, activation='relu')(dens_5)\n",
    "    dens_7 = Dense(16, activation='relu')(dens_6)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_7)\n",
    "\n",
    "    auto = Model(input_img, autoencoder3.layers[1](input_img), name=\"encoder\")    \n",
    "    dens_ = Model(encoder_dim, dens, name=\"dens_\")\n",
    "    \n",
    "    fc = Model(input_img, dens_(auto(input_img)), name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "\n",
    "    return fc\n",
    "\n",
    "dense3_auto(autoencoder3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 19, 19, 8)\n",
      "(None, None)\n",
      "Model: \"fc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 75, 75, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 38, 38, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 19, 19, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2888)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1024)              2958336   \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 3,665,006\n",
      "Trainable params: 3,665,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 8s 591us/step - loss: 1.5028 - accuracy: 0.3725 - val_loss: 1.5354 - val_accuracy: 0.3927\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 9s 653us/step - loss: 1.1481 - accuracy: 0.5548 - val_loss: 1.0422 - val_accuracy: 0.5887\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 9s 653us/step - loss: 0.9634 - accuracy: 0.6263 - val_loss: 0.8901 - val_accuracy: 0.6450\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 9s 651us/step - loss: 0.8558 - accuracy: 0.6704 - val_loss: 0.8089 - val_accuracy: 0.7010\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 9s 651us/step - loss: 0.7746 - accuracy: 0.7130 - val_loss: 0.9385 - val_accuracy: 0.6330\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 9s 658us/step - loss: 0.6867 - accuracy: 0.7448 - val_loss: 0.7589 - val_accuracy: 0.7217\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 9s 659us/step - loss: 0.6085 - accuracy: 0.7827 - val_loss: 0.8880 - val_accuracy: 0.6940\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 9s 652us/step - loss: 0.5182 - accuracy: 0.8123 - val_loss: 0.8127 - val_accuracy: 0.7250\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 9s 653us/step - loss: 0.4287 - accuracy: 0.8472 - val_loss: 1.1444 - val_accuracy: 0.6890\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 9s 651us/step - loss: 0.3322 - accuracy: 0.8849 - val_loss: 1.0826 - val_accuracy: 0.7250\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 9s 652us/step - loss: 0.2762 - accuracy: 0.9092 - val_loss: 1.1276 - val_accuracy: 0.7330\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 9s 653us/step - loss: 0.2328 - accuracy: 0.9272 - val_loss: 1.2857 - val_accuracy: 0.7247\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 9s 647us/step - loss: 0.1903 - accuracy: 0.9441 - val_loss: 1.4414 - val_accuracy: 0.7243\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 9s 650us/step - loss: 0.1634 - accuracy: 0.9505 - val_loss: 1.2348 - val_accuracy: 0.7200\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 9s 653us/step - loss: 0.1391 - accuracy: 0.9627 - val_loss: 1.5522 - val_accuracy: 0.7037\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 9s 644us/step - loss: 0.1115 - accuracy: 0.9689 - val_loss: 1.5076 - val_accuracy: 0.7213\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 9s 645us/step - loss: 0.1125 - accuracy: 0.9710 - val_loss: 1.3415 - val_accuracy: 0.7210\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 9s 644us/step - loss: 0.0963 - accuracy: 0.9747 - val_loss: 1.5172 - val_accuracy: 0.7213\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 9s 649us/step - loss: 0.1193 - accuracy: 0.9715 - val_loss: 1.3945 - val_accuracy: 0.7297\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 10s 680us/step - loss: 0.1023 - accuracy: 0.9765 - val_loss: 1.2501 - val_accuracy: 0.7147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fdc1bd9ffd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense3():\n",
    "    input_img = Input(shape=(150, 150, 3))    \n",
    "  \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    print(x.shape)\n",
    "    dens_1 = Dense(1024, activation='relu')(x)\n",
    "    dens_2 = Dense(512, activation='relu')(dens_1)\n",
    "    dens_3 = Dense(256, activation='relu')(dens_2)\n",
    "    dens_4 = Dense(128, activation='relu')(dens_3)\n",
    "    dens_5 = Dense(64, activation='relu')(dens_4)\n",
    "    dens_6 = Dense(32, activation='relu')(dens_5)\n",
    "    dens_7 = Dense(16, activation='relu')(dens_6)\n",
    "\n",
    "    dens = Dense(6, activation='softmax')(dens_7)\n",
    "\n",
    "    \n",
    "    fc = Model(input_img, dens, name=\"fc\")\n",
    "    \n",
    "    fc.summary()\n",
    "    fc.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    fc.fit(train_images, train_labels, epochs=20, batch_size=128, shuffle=True, validation_data=(test_images,  test_labels))\n",
    "\n",
    "    return fc\n",
    "\n",
    "dense3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
