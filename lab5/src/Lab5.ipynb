{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.nasnet import NASNetLarge\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH = 128\n",
    "image_size = 150\n",
    "def generator():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_data = datagen.flow_from_directory('/kaggle/input/intel-image-classification/seg_train/seg_train/',\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        batch_size=BATCH,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "    test_data = datagen.flow_from_directory('/kaggle/input/intel-image-classification/seg_test/seg_test/',\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        batch_size=BATCH,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "    return train_data, test_data\n",
    "train_data, test_data = generator()\n",
    "train_images, train_labels = train_data.next()\n",
    "test_images, test_labels = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "(56, 150, 150, 3)\n",
      "110\n",
      "(82, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))\n",
    "print(test_data[23][0].shape)\n",
    "\n",
    "print(len(train_data))\n",
    "print(train_data[109][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 150, 150, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0,\n",
       " 'forest': 1,\n",
       " 'glacier': 2,\n",
       " 'mountain': 3,\n",
       " 'sea': 4,\n",
       " 'street': 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Tue Dec 24 11:16:11 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pprint\n",
    "\n",
    "sp = subprocess.Popen(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "out_str = sp.communicate()\n",
    "out_list = str(out_str[0]).split('\\\\n')\n",
    "\n",
    "out_dict = {}\n",
    "\n",
    "for item in out_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент 1\n",
    "Использование структуры глубокой модели, построенной для решения исходной «Задачи А», с целью обучения аналогичной модели для решения «Задачи В»\n",
    "* Предполагается, что модель, построенная для решения исходной задачи, обучается на данных, подготовленных для\n",
    "решения целевой задачи\n",
    "* При этом веса модели инициализируются случайным образом\n",
    "* Эксперимент реализует перенос знаний для родственных доменов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем VGG16 - модель для решения задачи ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              8193000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 22,913,694\n",
      "Trainable params: 22,913,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ACTIVATION='relu'\n",
    "KERNEL_INIT='he_normal'\n",
    "vgg_model = Sequential()\n",
    "vgg_model.add(VGG16(include_top=False, weights=None, input_shape=(image_size, image_size, 3), classes=6))\n",
    "vgg_model.add(layers.Flatten())\n",
    "vgg_model.add(layers.Dense(1000, activation=ACTIVATION, input_dim=4*4*512, kernel_initializer=KERNEL_INIT))\n",
    "vgg_model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 110 steps, validate for 24 steps\n",
      "Epoch 1/20\n",
      "110/110 [==============================] - 66s 601ms/step - loss: 1394.3259 - accuracy: 0.1816 - val_loss: 1.7916 - val_accuracy: 0.1750\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 53s 479ms/step - loss: 1.8321 - accuracy: 0.1719 - val_loss: 1.7909 - val_accuracy: 0.1790\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 53s 480ms/step - loss: 1.8653 - accuracy: 0.1768 - val_loss: 1.7853 - val_accuracy: 0.1750\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 53s 481ms/step - loss: 3.7933 - accuracy: 0.1905 - val_loss: 1.7903 - val_accuracy: 0.1750\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 53s 479ms/step - loss: 2.1756 - accuracy: 0.1939 - val_loss: 1.6877 - val_accuracy: 0.2503\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 53s 478ms/step - loss: 2.1238 - accuracy: 0.2173 - val_loss: 1.7889 - val_accuracy: 0.1670\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 53s 478ms/step - loss: 1.8309 - accuracy: 0.2547 - val_loss: 1.6249 - val_accuracy: 0.4210\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 53s 478ms/step - loss: 1.7926 - accuracy: 0.2939 - val_loss: 1.5880 - val_accuracy: 0.3540\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 53s 481ms/step - loss: 1.3529 - accuracy: 0.4705 - val_loss: 1.1386 - val_accuracy: 0.5057\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 53s 480ms/step - loss: 1.0727 - accuracy: 0.5628 - val_loss: 0.9167 - val_accuracy: 0.6137\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 53s 480ms/step - loss: 0.9797 - accuracy: 0.6087 - val_loss: 0.8285 - val_accuracy: 0.6723\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 53s 479ms/step - loss: 0.9030 - accuracy: 0.6486 - val_loss: 0.7454 - val_accuracy: 0.7103\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 53s 481ms/step - loss: 0.8420 - accuracy: 0.6878 - val_loss: 0.7789 - val_accuracy: 0.7020\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 53s 479ms/step - loss: 0.7585 - accuracy: 0.7124 - val_loss: 0.7094 - val_accuracy: 0.7203\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 53s 480ms/step - loss: 0.6947 - accuracy: 0.7374 - val_loss: 0.7290 - val_accuracy: 0.7413\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 53s 482ms/step - loss: 0.6600 - accuracy: 0.7531 - val_loss: 0.6314 - val_accuracy: 0.7633\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 53s 480ms/step - loss: 0.6103 - accuracy: 0.7754 - val_loss: 0.6906 - val_accuracy: 0.7447\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 53s 479ms/step - loss: 0.5562 - accuracy: 0.7958 - val_loss: 0.6223 - val_accuracy: 0.7663\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 53s 478ms/step - loss: 0.5099 - accuracy: 0.8110 - val_loss: 0.5606 - val_accuracy: 0.8003\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 53s 478ms/step - loss: 0.4934 - accuracy: 0.8225 - val_loss: 0.5349 - val_accuracy: 0.8157\n",
      "Time:  0:17:48.706916\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "vgg_model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "time_start = datetime.now()\n",
    "history = vgg_model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\n",
    "time = datetime.now() - time_start\n",
    "print('Time: ', time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент 2\n",
    "Использование модели, построенной для решения исходной «Задачи А», в качестве фиксированного\n",
    "метода извлечения признаков при построении модели, решающей «Задачу В»\n",
    "* Идея данного подхода состоит в том, чтобы удалить из глубокой модели классификатор (последние полностью\n",
    "связанные слои) и рассматривать начальную часть сети как метод выделения признаков\n",
    "* Взамен старого классификатора можно поместить новый классификатор (например, другой набор полностью\n",
    "связанных слоев или машину опорных векторов) и обучить его на признаках, построенных с использованием начальной\n",
    "части сети\n",
    "* Эксперимент реализует перенос признакового описания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем за основу сверточную нейронную сеть VGG16, обученную на наборе ImageNet (1,4 миллиона изобр, классифицированных на 1000 классов).\n",
    "\n",
    "Пропустим набор данных intel-image через предварительно обученную сверточную основу VGG16, запишем результат.\n",
    "\n",
    "Используем результат как входные данные для отдельного полносвязного классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3), classes=1000)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sample_count, vgg_model, generat):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count, 6))\n",
    "    i=0\n",
    "    for inputs_batch, labels_batch in generat:\n",
    "        #выделяем признаки из изображений\n",
    "        features_batch = vgg_model.predict(inputs_batch)\n",
    "        features[i * BATCH : (i + 1) * BATCH] = features_batch\n",
    "        labels[i * BATCH : (i + 1) * BATCH] = labels_batch\n",
    "        i = i + 1\n",
    "        if (i + 1) * BATCH >= sample_count:\n",
    "            return features, labels\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n",
      "Time:  0:00:56.887767\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "train_sample_count = 14034\n",
    "test_sample_count = 3000\n",
    "generat = generator()\n",
    "#выделяем признаки\n",
    "train_features, train_y = extract_features(train_sample_count, vgg_model, generat[0])\n",
    "test_features, test_y = extract_features(test_sample_count, vgg_model, generat[1])\n",
    "\n",
    "time = datetime.now() - time_start\n",
    "print('Time: ', time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14034, 4, 4, 512)\n",
      "(14034, 6)\n",
      "(3000, 4, 4, 512)\n",
      "(3000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(test_features.shape) \n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (train_sample_count, 4*4*512))\n",
    "test_features = np.reshape(test_features, (test_sample_count, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14034, 8192)\n",
      "(14034, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1000)              8193000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 8,199,006\n",
      "Trainable params: 8,199,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14034 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "14034/14034 [==============================] - 2s 118us/sample - loss: 1.2050 - accuracy: 0.7291 - val_loss: 0.4148 - val_accuracy: 0.8413\n",
      "Epoch 2/20\n",
      "14034/14034 [==============================] - 1s 76us/sample - loss: 0.4366 - accuracy: 0.8395 - val_loss: 0.6488 - val_accuracy: 0.7817\n",
      "Epoch 3/20\n",
      "14034/14034 [==============================] - 1s 78us/sample - loss: 0.3457 - accuracy: 0.8712 - val_loss: 0.3623 - val_accuracy: 0.8587\n",
      "Epoch 4/20\n",
      "14034/14034 [==============================] - 1s 79us/sample - loss: 0.2773 - accuracy: 0.8966 - val_loss: 0.3418 - val_accuracy: 0.8753\n",
      "Epoch 5/20\n",
      "14034/14034 [==============================] - 1s 79us/sample - loss: 0.2347 - accuracy: 0.9083 - val_loss: 0.3556 - val_accuracy: 0.8783\n",
      "Epoch 6/20\n",
      "14034/14034 [==============================] - 1s 77us/sample - loss: 0.2003 - accuracy: 0.9215 - val_loss: 0.3682 - val_accuracy: 0.8837\n",
      "Epoch 7/20\n",
      "14034/14034 [==============================] - 1s 77us/sample - loss: 0.1634 - accuracy: 0.9356 - val_loss: 0.3474 - val_accuracy: 0.8900\n",
      "Epoch 8/20\n",
      "14034/14034 [==============================] - 1s 79us/sample - loss: 0.1399 - accuracy: 0.9487 - val_loss: 0.3683 - val_accuracy: 0.8883\n",
      "Epoch 9/20\n",
      "14034/14034 [==============================] - 1s 76us/sample - loss: 0.1143 - accuracy: 0.9551 - val_loss: 0.4297 - val_accuracy: 0.8827\n",
      "Epoch 10/20\n",
      "14034/14034 [==============================] - 1s 76us/sample - loss: 0.0982 - accuracy: 0.9596 - val_loss: 0.5318 - val_accuracy: 0.8547\n",
      "Epoch 11/20\n",
      "14034/14034 [==============================] - 1s 79us/sample - loss: 0.0818 - accuracy: 0.9639 - val_loss: 0.5380 - val_accuracy: 0.8450\n",
      "Epoch 12/20\n",
      "14034/14034 [==============================] - 1s 76us/sample - loss: 0.0680 - accuracy: 0.9711 - val_loss: 0.6053 - val_accuracy: 0.8497\n",
      "Epoch 13/20\n",
      "14034/14034 [==============================] - 1s 79us/sample - loss: 0.0621 - accuracy: 0.9735 - val_loss: 0.5142 - val_accuracy: 0.8707\n",
      "Epoch 14/20\n",
      "14034/14034 [==============================] - 1s 79us/sample - loss: 0.0537 - accuracy: 0.9765 - val_loss: 0.5610 - val_accuracy: 0.8603\n",
      "Epoch 15/20\n",
      "14034/14034 [==============================] - 1s 78us/sample - loss: 0.0521 - accuracy: 0.9778 - val_loss: 0.5904 - val_accuracy: 0.8590\n",
      "Epoch 16/20\n",
      "14034/14034 [==============================] - 1s 78us/sample - loss: 0.0559 - accuracy: 0.9784 - val_loss: 0.5472 - val_accuracy: 0.8737\n",
      "Epoch 17/20\n",
      "14034/14034 [==============================] - 1s 78us/sample - loss: 0.0543 - accuracy: 0.9812 - val_loss: 0.5772 - val_accuracy: 0.8713\n",
      "Epoch 18/20\n",
      "14034/14034 [==============================] - 1s 77us/sample - loss: 0.0374 - accuracy: 0.9846 - val_loss: 0.7059 - val_accuracy: 0.8587\n",
      "Epoch 19/20\n",
      "14034/14034 [==============================] - 1s 78us/sample - loss: 0.0379 - accuracy: 0.9835 - val_loss: 0.7038 - val_accuracy: 0.8677\n",
      "Epoch 20/20\n",
      "14034/14034 [==============================] - 1s 79us/sample - loss: 0.0446 - accuracy: 0.9825 - val_loss: 0.6513 - val_accuracy: 0.8677\n",
      "Time:  0:00:23.395772\n"
     ]
    }
   ],
   "source": [
    "#передадим полученные признаки на вход полносвязному классификатору\n",
    "EPOCHS = 20\n",
    "ACTIVATION='relu'\n",
    "KERNEL_INIT='he_normal'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(1000, activation=ACTIVATION, input_dim=4*4*512, kernel_initializer=KERNEL_INIT))\n",
    "\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "time_start = datetime.now()\n",
    "history = model.fit(train_features, train_y, epochs=EPOCHS, batch_size = 128, shuffle=True, validation_data=(test_features, test_y))\n",
    "time = datetime.now() - time_start\n",
    "print('Time: ', time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент 3\n",
    "Тонкая настройка параметров модели, построенной для решения исходной «Задачи А», с целью решения\n",
    "«Задачи В»\n",
    "* Последние слои глубокой модели, соответствующие классификатору, который решает «Задачу А», заменяются\n",
    "новым классификатором (например, набором полностью связанных слоев с другим количеством выходов)\n",
    "* Полученная модель обучается как единая система \n",
    "* Эксперимент реализует перенос обучения на основе\n",
    "экземпляров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3), classes=1000)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              8193000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 22,913,694\n",
      "Trainable params: 8,199,006\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Train for 110 steps, validate for 24 steps\n",
      "Epoch 1/20\n",
      "110/110 [==============================] - 35s 322ms/step - loss: 1.2433 - accuracy: 0.7334 - val_loss: 0.3783 - val_accuracy: 0.8577\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 0.4418 - accuracy: 0.8364 - val_loss: 0.4041 - val_accuracy: 0.8440\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 33s 301ms/step - loss: 0.3435 - accuracy: 0.8671 - val_loss: 0.3252 - val_accuracy: 0.8810\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 33s 299ms/step - loss: 0.2905 - accuracy: 0.8906 - val_loss: 0.3428 - val_accuracy: 0.8770\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 0.2504 - accuracy: 0.9039 - val_loss: 0.3610 - val_accuracy: 0.8780\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 0.2124 - accuracy: 0.9186 - val_loss: 0.4414 - val_accuracy: 0.8583\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 34s 308ms/step - loss: 0.1748 - accuracy: 0.9359 - val_loss: 0.3736 - val_accuracy: 0.8830\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 33s 304ms/step - loss: 0.1490 - accuracy: 0.9453 - val_loss: 0.3611 - val_accuracy: 0.8783\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 34s 309ms/step - loss: 0.1164 - accuracy: 0.9584 - val_loss: 0.5152 - val_accuracy: 0.8637\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 34s 312ms/step - loss: 0.1072 - accuracy: 0.9603 - val_loss: 0.4269 - val_accuracy: 0.8870\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 33s 305ms/step - loss: 0.0860 - accuracy: 0.9674 - val_loss: 0.4660 - val_accuracy: 0.8760\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 33s 304ms/step - loss: 0.0728 - accuracy: 0.9719 - val_loss: 0.4921 - val_accuracy: 0.8883\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 33s 302ms/step - loss: 0.0647 - accuracy: 0.9784 - val_loss: 0.5118 - val_accuracy: 0.8867\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 34s 310ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 0.6359 - val_accuracy: 0.8740\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 34s 305ms/step - loss: 0.0565 - accuracy: 0.9836 - val_loss: 0.7851 - val_accuracy: 0.8517\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 34s 306ms/step - loss: 0.0492 - accuracy: 0.9858 - val_loss: 1.1991 - val_accuracy: 0.8117\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 34s 305ms/step - loss: 0.0431 - accuracy: 0.9875 - val_loss: 0.5826 - val_accuracy: 0.8897\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 34s 307ms/step - loss: 0.0656 - accuracy: 0.9858 - val_loss: 0.6130 - val_accuracy: 0.8883\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 34s 306ms/step - loss: 0.0362 - accuracy: 0.9918 - val_loss: 1.0306 - val_accuracy: 0.8443\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 34s 306ms/step - loss: 0.0412 - accuracy: 0.9911 - val_loss: 0.7124 - val_accuracy: 0.8817\n",
      "Time:  0:11:15.125171\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "ACTIVATION='relu'\n",
    "KERNEL_INIT='he_normal'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "vgg_model.trainable = False\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1000, activation=ACTIVATION, input_dim=4*4*512, kernel_initializer=KERNEL_INIT))\n",
    "\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "time_start = datetime.now()\n",
    "history =  model.fit_generator(train_data, steps_per_epoch=len(train_data), shuffle=True, epochs=EPOCHS, validation_steps=len(test_data), validation_data=test_data)\n",
    "time = datetime.now() - time_start\n",
    "print('Time: ', time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
